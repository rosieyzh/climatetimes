{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(result_link):\n",
    "    \"\"\"Gets all article links on a given page on a news site\"\"\"\n",
    "    links=[]\n",
    "    r = requests.get(result_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    links_results = soup.findAll('h2', {\"class\":\"entry-title\"}) #Gets article link wrappers\n",
    "    \n",
    "    for result in links_results:\n",
    "        links.append(result.find('a').get('href'))\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_text(article_link):\n",
    "    \"\"\"Takes in a link to an article and returns the formatted article as text\"\"\"\n",
    "    article=\"\"\n",
    "    r = requests.get(article_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    article_body = soup.find(class_='entry')\n",
    "\n",
    "#     print(article_body.findAll('p'))\n",
    "    for p in article_body.findAll('p'):\n",
    "        excerpt = p.text.replace(u'\\xa0', u' ')\n",
    "        article = article + \" \" + excerpt\n",
    "        \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 2, total articles: 15"
     ]
    }
   ],
   "source": [
    "articles=[]\n",
    "MAX_PAGES = 21\n",
    "\n",
    "# get_links('http://www.globalclimatescam.com/page/2/')\n",
    "\n",
    "for i in range(1, MAX_PAGES):\n",
    "    sys.stdout.write(\"\\rPage: {}, total articles: {}\".format(i, len(articles)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    links = get_links('http://www.globalclimatescam.com/page/{}/'.format(i))\n",
    "    \n",
    "    for link in links:\n",
    "        articles.append(get_text(link))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. articles: 3977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>denial?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original title before update: Breaking: Dr. T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From Legal Insurrection Posted by Leslie East...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From Zerohedge Many people theorized that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From Gizmodo:  DNC Votes 222-137 Against Allo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From The Daily Caller August 22, 2019 4:55 PM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  denial?\n",
       "0   Original title before update: Breaking: Dr. T...        1\n",
       "1   From Legal Insurrection Posted by Leslie East...        1\n",
       "2   From Zerohedge Many people theorized that the...        1\n",
       "3   From Gizmodo:  DNC Votes 222-137 Against Allo...        1\n",
       "4   From The Daily Caller August 22, 2019 4:55 PM...        1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles2 = list(filter(None, articles)) \n",
    "df = pd.DataFrame(articles2, columns=['article']).drop_duplicates(keep='first')\n",
    "df['denial?'] = [1]*len(df.index)\n",
    "print('Num. articles: {}'.format(len(df)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54     Reposted from The Fabius Maximus Blog Larry K...\n",
       "55     Guest geology/geophysics drive-by by David Mi...\n",
       "56     Guest Post by Willis Eschenbach Thereâ€™s an ol...\n",
       "57     Guest essay by Eric Worrall h/t Dr. Willie So...\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/data_wattsup.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
