{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(result_link):\n",
    "    \"\"\"Gets all article links on a given page on a news site\"\"\"\n",
    "    links=[]\n",
    "    r = requests.get(result_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    links_results = soup.findAll('h2', {\"class\":\"entry-title\"}) #Gets article link wrappers\n",
    "    \n",
    "    for result in links_results:\n",
    "        links.append(result.find('a').get('href'))\n",
    "\n",
    "    return links\n",
    "\n",
    "def get_text(article_link):\n",
    "    \"\"\"Takes in a link to an article and returns the formatted article as text\"\"\"\n",
    "    article=\"\"\n",
    "    r = requests.get(article_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    article_body = soup.find(class_='entry')\n",
    "\n",
    "#     print(article_body.findAll('p'))\n",
    "    for p in article_body.findAll('p'):\n",
    "        excerpt = p.text.replace(u'\\xa0', u' ')\n",
    "        article = article + \" \" + excerpt\n",
    "        \n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 20, total articles: 285"
     ]
    }
   ],
   "source": [
    "articles=[]\n",
    "MAX_PAGES = 21\n",
    "\n",
    "# get_links('http://www.globalclimatescam.com/page/2/')\n",
    "\n",
    "for i in range(1, MAX_PAGES):\n",
    "    sys.stdout.write(\"\\rPage: {}, total articles: {}\".format(i, len(articles)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    links = get_links('http://www.globalclimatescam.com/page/{}/'.format(i))\n",
    "    \n",
    "    for link in links:\n",
    "        articles.append(get_text(link))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. articles: 297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>denial?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In honor of Al Gore’s new movie Elmer and th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By Elmer Beauregard 1. The Globe Isn’t Warmi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Judith Curry\\nPresident, Climate Forecas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CNBC.com\\n Environmental Protection Agency Ad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By Elmer Beauregard I decided to put part of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  denial?\n",
       "0    In honor of Al Gore’s new movie Elmer and th...        1\n",
       "1    By Elmer Beauregard 1. The Globe Isn’t Warmi...        1\n",
       "2    Dr. Judith Curry\\nPresident, Climate Forecas...        1\n",
       "3   CNBC.com\\n Environmental Protection Agency Ad...        1\n",
       "4    By Elmer Beauregard I decided to put part of...        1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles2 = list(filter(None, articles)) \n",
    "df = pd.DataFrame(articles2, columns=['article']).drop_duplicates(keep='first')\n",
    "df['denial?'] = [1]*len(df.index)\n",
    "print('Num. articles: {}'.format(len(df)))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54     Reposted from The Fabius Maximus Blog Larry K...\n",
       "55     Guest geology/geophysics drive-by by David Mi...\n",
       "56     Guest Post by Willis Eschenbach There’s an ol...\n",
       "57     Guest essay by Eric Worrall h/t Dr. Willie So...\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/data_wattsup.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
