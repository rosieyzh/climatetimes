{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(page_link):\n",
    "    headlines=[]\n",
    "    stories=[]\n",
    "    titles=[]\n",
    "    dates=[]\n",
    "    r = requests.get(page_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    content = soup.find('div', {'class':'topic_content'})\n",
    "\n",
    "    \n",
    "    for article in content.findAll('div', {'class':'news_item'}):\n",
    "        #get date\n",
    "        dates.append(article.find('span', {'class':'date'}).text)\n",
    "        \n",
    "        a_tag = article.find('a', attrs={'data-ga-action': 'Topic: Story Headline'})\n",
    "        link = \"https://www.democracynow.org\"+a_tag['href']\n",
    "        #get title\n",
    "        titles.append(a_tag.text)\n",
    "        if 'headlines' in link:\n",
    "            headlines.append(link)\n",
    "        else:\n",
    "            stories.append(link)\n",
    "    return headlines, stories, titles, dates\n",
    "\n",
    "def get_text(page_link, category):\n",
    "    '''\n",
    "        Category: Headline or Story\n",
    "    '''\n",
    "    article=''\n",
    "    r=requests.get(page_link)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    if category == 'headline':\n",
    "        headline_summary = soup.find('div', {'class':'headline_summary'})\n",
    "        for p in headline_summary.findAll('p'):\n",
    "            article = article + \"¶\" + p.text.replace(u'\\xa0', u' ')\n",
    "    elif category == 'story':\n",
    "        #story summary\n",
    "        summary = soup.find('div', {'class':'story_summary'})\n",
    "        for p in summary.findAll('p'):\n",
    "            article = article + \"¶\" + p.text.replace(u'\\xa0', u' ')\n",
    "        #story transcript\n",
    "        transcript = soup.find('div', {'id':'transcript'})\n",
    "        #remove strong tags of speaker name in transcript\n",
    "        if transcript:\n",
    "            [s.extract() for s in transcript('strong')]\n",
    "            for p in transcript.findAll('p'):\n",
    "                article = article + \"¶\" + p.text.replace(u'\\xa0', u' ')\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping from all pages\n",
    "democracynow_articles=[]\n",
    "democracynow_titles=[]\n",
    "democracynow_dates=[]\n",
    "for i in range(1, 131):\n",
    "    headlines, stories, titles, dates = get_links(\"https://www.democracynow.org/topics/climate_change/{}\".format(i))\n",
    "    democracynow_titles.extend(titles)\n",
    "    democracynow_dates.extend(dates)\n",
    "    for headline in headlines:\n",
    "        democracynow_articles.append(get_text(headline, category='headline'))\n",
    "    for story in stories:\n",
    "        democracynow_articles.append(get_text(story, category='story'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(democracynow_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_shorter=[]\n",
    "for article in democracynow_articles:\n",
    "    if len(article)<=30000:\n",
    "        articles_shorter.append(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles_shorter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¶Activists from the group Greenpeace hung a massive, 70-by-35-foot banner reading ”RESIST” from a crane only blocks from the White House Wednesday. This is Greenpeace’s Nancy Hernandez.¶Nancy Hernandez: “I’m standing here on top of a crane 300 feet in the air over the White House, where we have just deployed a banner. And this banner, it is a message to this administration. But more than that, this is a hand-painted love letter to you. This is a message to the people.”'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "democracynow_articles[650]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(democracynow_articles, columns=['content'])\n",
    "df['title']=democracynow_titles\n",
    "df['author']=['NaN']*len(df.index)\n",
    "df['date']=democracynow_dates\n",
    "df['denial?'] = [0]*len(df.index)\n",
    "cols=['title','author','date','content','denial?']\n",
    "df=df[cols]\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv('../../data/left/data_democracynow_articles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "aiml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
