{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\owner\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Doc2Vec model on left and right articles. I followed along to the IMDB tutorial from gojomo\"\"\"\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets left and right data files\n",
    "df1 = pd.read_csv('../../data/all_left_filtered.csv')\n",
    "df2 = pd.read_csv('../../data/all_right_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles1 = list(df1['content'])\n",
    "articles2 = list(df2['content'])\n",
    "\n",
    "#Runs the preprocessing method on both articles\n",
    "left = utils.preprocess(articles1)\n",
    "right = utils.preprocess(articles2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Key', 'event', '1988', 'EPA', 'decided', 'classify', 'oil', 'gas', 'waste', 'non'] 0\n"
     ]
    }
   ],
   "source": [
    "def merge(list1, list2): \n",
    "    \"\"\"Merge lists together into tuple\"\"\"\n",
    "    merged_list = tuple(zip(list1, list2))  \n",
    "    return merged_list \n",
    "\n",
    "denial0 = list(df1['denial?'])\n",
    "denial1 = list(df2['denial?'])\n",
    "\n",
    "left_tuples = merge(left, denial0)\n",
    "right_tuples = merge(right, denial1)\n",
    "all_articles = left_tuples+right_tuples\n",
    "print(all_articles[0][0][0:10], all_articles[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelledDocument(words=['Key', 'event', '1988', 'EPA', 'decided', 'classify', 'oil', 'gas', 'waste', 'non', 'hazardous', 'even', 'though', 'contains', 'dangerous', 'chemicals', 'small', 'town', 'Nordheim', 'Texas', 'residents', 'trying', 'stop', 'commercial', 'oil', 'gas', 'waste', 'facility', 'proposed', 'large', 'plot', 'land', 'less', 'mile', 'away', 'worry', 'Texas', 'wind', 'carry', 'toxic', 'air', 'emissions', 'town', 'across', 'campus', 'local', 'school', 'residents', 'effort', 'hampered', 'U', 'Environmental', 'Protection', 'Agency', 'decision', '1988', 'classify', 'oil', 'gas', 'waste', 'non', 'hazardous', 'even', 'though', 'contains', 'chemicals', 'including', 'benzene', 'known', 'cause', 'health', 'problems', 'industry', 'lobbied', 'hard', 'non', 'hazardous', 'classification', 'arguing', 'cost', 'treating', 'waste', 'hazardous', 'would', 'exorbitant', 'look', 'exemption', 'came', 'recent', 'effort', 'repeal', 'READ', 'Open', 'Pits', 'Offer', 'Cheap', 'Disposal', 'Fracking', 'Sludge', 'Health', 'Worries', 'Mount', 'Click', 'enlarge'], tags=[0], denial=0)\n",
      "Wall time: 351 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "\n",
    "# this data object class suffices as a `TaggedDocument` (with `words` and `tags`) \n",
    "LabelledDocument = namedtuple('LabelledDocument', 'words tags denial')\n",
    "\n",
    "alldocs = []\n",
    "\n",
    "#Converts each article to a TaggedDocument and puts in the alldocs list\n",
    "for i in range(len(all_articles)):\n",
    "    words = all_articles[i][0]\n",
    "    denial = all_articles[i][1]\n",
    "    tags = [i]\n",
    "    alldocs.append(LabelledDocument(words, tags, denial))\n",
    "    \n",
    "print(alldocs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffles the doclist\n",
    "from random import shuffle\n",
    "doc_list = alldocs[:]  \n",
    "shuffle(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t4) vocabulary scanned & state initialized\n",
      "Wall time: 37.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "#Trains 3 models with different params\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some other models to test\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "Wall time: 5min 17s\n",
      "Training Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "Wall time: 6min 27s\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "Wall time: 10min 2s\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#Training models\n",
    "for model in simple_models: \n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(doc_list, total_examples=len(doc_list), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (12498): «Fridge freezer left ditch Malcolm Campbell CC SA 2 0 via Wikimedia Commons Guest essay Eric Worrall According Time Magazine forcing everyone switch CFC refrigerants climate friendly refrigerants job creation opportunity One Climate Change Deal Trump Administration Might Back JUSTIN WORLAND February 6 2018 Trump Administration hesitated throw key deal reached 2016 phase pollutant found air conditioners factor climate change part American companies think could huge business opportunity Administration official declined say Monday whether Trump would send Kigali amendment Senate ratification president wants make sure international environment agreement harm U workers said George David Banks White House international energy environment advisor event Hudson Institute Monday president decide support Kigali largely wants create U jobs want global leaders like alway industry says Stephen Yurek CEO Air Conditioning Heating Refrigeration Institute pick products technology pick developed countries ratified amendment Banks says Trump Administration still questions understand broad industry support said Banks first need know economic impact Read http time com 5134208 kigali amendment donald trump climate change frequently shocked total ignorance economics displayed today journalists Kigali amendment compliant air conditioners big international export opportunity US manufacture Kigali compliant air conditioners export subsidised forcing everyone USA switch new standard air conditioner manufacturers fund opportunity using capital silliest part Time article claim forced switch job creation opportunity Long ago famous economist Frédéric Bastiat invented parable broken window explain wrong belief imposing costs stimulates economic activity ever witnessed anger good shopkeeper James Goodfellow careless son happened break pane glass present scene assuredly bear witness fact every one spectators even thirty common consent apparently offered unfortunate owner invariable consolation ill wind blows nobody good Everybody must live would become glaziers panes glass never broken form condolence contains entire theory well show simple case seeing precisely unhappily regulates greater part economical institutions Suppose cost six francs repair damage say accident brings six francs glazier trade encourages trade amount six francs grant word say reason justly glazier comes performs task receives six francs rubs hands heart blesses careless child seen hand come conclusion often case good thing break windows causes money circulate encouragement industry general result oblige call Stop theory confined seen takes account seen seen shopkeeper spent six francs upon one thing cannot spend upon another seen window replace would perhaps replaced old shoes added another book library short would employed six francs way accident prevented https en wikipedia org wiki Parable_of_the_broken_window forced switch perfectly adequate existing standard new standard best delivers facility job opportunity pointless government imposed cost kind pointless bureaucratic cost President Trump pledged eliminate Every job created air conditioner industry imposing Kigali Amendment would matched jobs lost industries businesses would forced reduce expenditures comply useless new standard Worse countries bother enforce new standards whose implementation new standard delayed USA course agreed early adopter expensive new standard obtain economic advantage US companies forced pay product upgrade neither need want Lets hope President Trump sensible thing tosses useless climate standard US manufacturers want produce air conditioning units comply Kigali amendment export free utterly unreasonable expect everyone else America pay export venture forced purchases upgrade delivers value purchaser cost would ultimately passed ordinary Americans»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow,d100,n5,mc2,t4):\n",
      "\n",
      "MOST (12007, 0.6013211011886597): «Last June President Trump announced would withdraw U Paris Agreement climate treaty greenhouse gases bold move defying legions foreign leaders U politicians corporate CEOs media pundits activist groups faster way chosen take December 12 second anniversary adoption Agreement making fitting occasion restate obvious remaining treaty endangers U economy Constitution treaty process nation political independence bad effects stem fact President Obama aware Senate unlikely approve treaty bypassed constitutional ratification process declared executive agreement instead President Trump certainly correct Obama negotiated bad deal process Obama pledge reduce U greenhouse gas emissions 26 28 per cent 2005 levels 2025 U nationally determined contribution NDC U N parlance would significant adverse impacts U jobs household income economic growth contrast China India NDCs essentially commit countries follow current emissions trajectory Even 195 signatory nations implement NDCs Agreement discernible effect climate change America Paris Agreement great pain gain exit option President Trump selected comes Paris Agreement takes four years complete decision also provisional meaning America withdraw unless negotiate better deal fair effect Mr Trump invited pro Paris advocates try change mind gave lots time sure governments may willing accept drill baby drill Trump new NDC long America pays billions climate finance foreign aid Nonetheless staying Agreement would still imperil vital U interests First would validate President Obama evasion Constitution treaty process approval pact without obtaining Senate advice consent Paris Agreement treaty virtue potential costs nation whole dependence subsequent legislation Congress traditional treaty criteria telling virtually parties including non democratic regimes like China ratified Agreement legislatures Obama collusion foreign elites adopt unpopular treaty deeming treaty becomes constitutionally damaging precedent unless President Trump overturns Second NDC promises non binding international law would make harmless elected officials immune political pressure laughable idea balked harm would cause Governments honor non binding NDCs however turning binding laws regulations Paris Agreement reality designed mobilize permanent global campaign name shame policymakers fail rig energy markets fossil fuels Agreement effectively demands suppression America surging oil gas production major source new jobs geopolitical strength consumer savings competitive advantage would sensible person stay club organized browbeat acting best interests better judgment Moreover even non binding commitments create legal liabilities Netherlands government discovered Citing government endorsement non binding declarations previous U N climate conferences Hague District Court ordered Dutch policymakers match deeds words adopt tough new emission controls membership Agreement fuels regulatory tort litigation behalf alleged climate victims short revisions Obama NDC make Paris Agreement safe U merely following Agreement four year withdrawal procedure would allow new President rejoin 2021 pick Obama left would also nothing repair Obama breach treaty process Mr Trump instead send Agreement Senate ratification vote recommendation rejected virtually chance requisite two thirds Senators present would approve treaty Agreement dies Senate also exceedingly unlikely future executive would try rejoin unilaterally pretense ambitious climate pact history treaty follow treaty rules Mr President Follow Constitution»\n",
      "\n",
      "MEDIAN (10480, 0.2076452672481537): «study antifragile crowd aka Taleb would probably love ctm explore exploit Fishing vessel records show trade offs University California Davis making choices people tend either go know try something new experience trade every day whether choosing route work buying breakfast cereal one strategy advantage another Researchers decided examine question looking fishing boat captains face choice deciding fish find strategy leads greater success real world scientists University California Davis coauthors examined 540 000 fishing vessel position records nearly 2 500 commercial fishing trips U Gulf Mexico along revenues results published today journal Nature Communications looks like exploration pays face uncertainty said co leading author Shay Farrell postdoctoral researcher lab Professor James Sanchirico UC Davis Department Environmental Science Policy particularly important context global environmental change disturbances storms droughts predicted increase FUTURE PROOFING LIVELIHOODS study found vessels consistently explore new territory others invest time resources sampling new places fish times stability exploratory vessels performed better worse average vessels stuck consistency relatively stable environments would expect gains switching behaviors would usually go away otherwise vessels would changing fish Sanchirico said boats suddenly forced fish elsewhere 2009 closure popular fishing grounds Gulf history exploration experienced significantly less impact disruption may boat captains could draw history exploration select new grounds Farrell suggests findings may hold lessons times uncertainty One way future proof livelihoods exploring new options Farrell said way current options become unavailable less attractive future fall back knowledge alternatives Sharing knowledge could make us even resilient still draw larger pool experience study co leading authors also include Sanchirico UC Davis Coastal Marine Sciences Institute nonprofit Resources Future Orr Spiegel Tel Aviv University Additional co authors include Maxime Depalle UC Davis Alan Haynie NOAA Alaska Fisheries Science Center Steven Murawski University South Florida Larry Perruso NOAA Southeast Fisheries Science Center Andrew Strelcheck NOAA Southeast Regional Office study funded National Science Foundation Coastal SEES Grant National Academy Sciences Gulf Research Program Data Synthesis Grant EurekAlert»\n",
      "\n",
      "LEAST (1275, -0.10167516767978668): «Rising temperatures past 50 years kind glaciers climate change continuing giant ice slabs could soon disappear ruggedly stunning landscape Montana Glacier National Park still stunning rugged 50 years glaciers park named harder spot exist global temperatures warmed past half century park major named glaciers receded shrinking average 39 percent since 1966 according study released Wednesday U Geological Survey USGS Portland State University past 50 years glaciers shrunk 82 percent us soon said Daniel Fagre lead USGS scientist project others shrinkage modest 13 percent amount ice cases diminished long term prospects glaciers good Fagre colleagues analyzed measurements taken past five decades park 37 major glaciers two others adjacent U Forest Service land found 39 glaciers 26 still meet 25 acre threshold Glaciologists consider amount mass convenient cut point distinguish glacier perennial wedge ice snow moves stagnant ice perennial snowfield wedge ice snow founding 1910 Glacier National Park home 150 glaciers glaciers shrinking much end Little Ice Age park founding Fagre said referring global cooling period ended around 1715 loss occurred since Geologists USGS universities found similar glacial downsizing across West trying understand impact larger climate patterns different mountain environments working Sierra California working Olympics going start North Cascades summer emblematic happening West said Andrew Fountain professor geology geography Portland State University co author study impacts climate change glaciers could especially potent Rocky Mountains warming trends 1 8 times global average region increasingly prone drought wildfires scenario symptom glacier loss cause Locally speaking smaller glaciers produce much meltwater threatens local ecosystems especially late summer less capacity buffer droughts contribute water droughts Fountain said water going someplace going oceans even though happening mountains Florida feeling effects Within Glacier National Park impacts go beyond scenery aquatic species including insect called meltwater stonefly threatened changing conditions glaciers instrumental maintaining cold water certain aquatic organisms safety net gone organisms Fagre said early warning signal broader ecosystem change record 2 9 million visitors drawn nearly 1 600 square mile park last summer Fagre said Clearly park going glaciers past decades Fagre added beautiful landscape continue glaciers gone»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#Gets most similar, somewhat similar and least similar articles compared to a target article\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): «%s»\\n' % (doc_id, ' '.join(alldocs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(alldocs[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\owner\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "word_models = simple_models[:]\n",
    "\n",
    "#Saves the models\n",
    "for i in range(0, len(word_models)):\n",
    "    model.save(\"d2v{}.model\".format(i+1))\n",
    "    print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(alldocs)\n",
    "\n",
    "model3_vectors = []\n",
    "model3_labels = []\n",
    "\n",
    "# all_vectors2 = []\n",
    "# all_labels2 = []\n",
    "\n",
    "# all_vectors3 = []\n",
    "# all_labels3 = []\n",
    "\n",
    "#Putting vectors in one array, labels in another\n",
    "for i in range(len(alldocs)):\n",
    "    model3_vectors.append(simple_models[2].docvecs[i])\n",
    "    model3_labels.append(alldocs[i].denial)\n",
    "    \n",
    "import pickle\n",
    "\n",
    "with open('model3_vectors', 'wb') as fp:\n",
    "    pickle.dump(model3_vectors, fp)\n",
    "    \n",
    "with open('model3_vectors', 'wb') as fp:\n",
    "    pickle.dump(model3_labels, fp)\n",
    "# alldocs[367]\n",
    "# model['[367]']\n",
    "# simple_models[0]['[367]']\n",
    "# alldocs[366]\n",
    "# similar_doc = simple_models[0].docvecs.most_similar(0)\n",
    "# similar_doc\n",
    "# print(alldocs[367])\n",
    "# simple_models[0]['367']\n",
    "# simple_models[0][0]\n",
    "\n",
    "# simple_models[0].docvecs.count\n",
    "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
    "# print(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_labels1[0]\n",
    "#Training rf\n",
    "# utils.train_rf(all_vectors1, all_labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 94.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Model accuracy on test set: 86.14521220624343\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: \"best_svm_<class 'list'>.pb\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5c0bdd658d4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel3_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel3_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\climatetimes\\src\\models\\utils.py\u001b[0m in \u001b[0;36mtrain_svm\u001b[1;34m(features, labels, type)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;31m#Save model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_svm_{}.pb'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                 \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_svm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: \"best_svm_<class 'list'>.pb\""
     ]
    }
   ],
   "source": [
    "utils.train_svm(model3_vectors, model3_labels, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
